#!/usr/bin/env python3
import argparse
import os
import random
import subprocess
import concurrent.futures
import shutil
import multiprocessing
import psutil
import time
import threading
import platform
from functools import partial
from pathlib import Path
import sys
from runwithlimits import *

configfile: "config.yaml"

# get Git root
GIT_ROOT = Path(subprocess.check_output(
    ["git", "rev-parse", "--show-toplevel"]
).decode().strip())
print("Git root:", GIT_ROOT)

workdir: "../"

HACKERSDELIGHT_FILE_NAMES, = glob_wildcards(GIT_ROOT / "SSA/Projects/InstCombine/HackersDelight/{file}.lean")

SED = "gsed" if platform.system() == "Darwin" else "sed"
hdel_nreps = config["hdel_nreps"]

rule lakefresh:
  input:
    glob_wildcards(GIT_ROOT / "**.lean"),
    glob_wildcards(GIT_ROOT / "lakefile.*")
  output:
      GIT_ROOT / ".lake/build/lib/lean/SSA.olean"
  threads: 1
  shell:
    "echo 'Checking that lake is already built,If not, use \'lake exe cache get\' / \'lake build\'' && "
    "lake build --no-build"

rule hdel_compare_make_lean:
  input:
    GIT_ROOT / "SSA/Projects/InstCombine/HackersDelight/{file}.lean"
  output:
     GIT_ROOT / "bv-evaluation/results/HackersDelight/{file}_{width}_{hdel_nreps}.lean"
  shell:
    "cp {input} {output} && "
    "{SED} -i  -e \"s/all_goals sorry/all_goals bv_compare'/g\" -e \"s/WIDTH/{wildcards.width}/g\" {output} "


rule hdel_compare_make_output:
  input:
    olean=rules.lakefresh.output,
    infile=lambda wc: GIT_ROOT / f"bv-evaluation/results/HackersDelight/{wc.file}_{wc.width}_{hdel_nreps}.lean",
  output:
    GIT_ROOT / "bv-evaluation/results/HackersDelight/{file}_{width}_r{r}.txt"
  resources:
    # TODO: actually impose memory and time limit, using a python script.
  run:
    cmd = ["lake", "lean", input["infile"]]
    status, stdout, stderr = run_with_limits(cmd=cmd,
        cwd=GIT_ROOT,
        timeout=int(config["hdel_timeout_sec"]),
        memout_mb=int(config["hdel_memout_mb"]))
    if not isinstance(status, int) or status != 0:
        raise Exception(f"Running hackersdelight file (command '{cmd}') failed with status '{status}', stdout '{stdout}', stderr '{stderr}'.")
    with open(output[0], "w") as f:
        f.write(stdout)
        f.write(stderr)

# We can eventually split these, if we carefully understand the naming convention
# of 'collect' for hacker's delight.
# We currently make a monolithic job that runs both collect and plot,
# Since the naming convention is a little opaque to @bollu.
rule hdel_collect_and_plot:
  input:
    expand(GIT_ROOT / "bv-evaluation/results/HackersDelight/{file}_{width}_r{r}.txt",
      file=HACKERSDELIGHT_FILE_NAMES,
      width=config["hdel_bv_widths"],
      r=range(hdel_nreps))
  params:
    nreps = lambda wc: hdel_nreps,
    nthreads = lambda wc: config["hdel_nthreads"]
  output:
    tex=GIT_ROOT  / "bv-evaluation/performance-hackersdelight.tex",
    pdf_stacked=GIT_ROOT / "bv-evaluation/plots/bv_decide_stacked_perc_HackersDelight_bvw64.pdf"
    # TODO: track the exact files generated by 'collect.py'.
    # We currently just bother asking for the two outputs we care for.
  shell:
    "bash -c 'source {GIT_ROOT}/.venv/bin/activate && cd bv-evaluation && python3 collect.py hackersdelight' && "
    "bash -c 'source {GIT_ROOT}/.venv/bin/activate && cd bv-evaluation && python3 plot.py hackersdelight'"


rule all:
  input:
    rules.lakefresh.output,
    rules.hdel_collect_and_plot.output
  default_target: True

