-- AUTOGENERATED Lean file

import SSA.Projects.LLVMRiscV.PeepholeRefine
import SSA.Projects.LLVMRiscV.Simpproc
import SSA.Projects.RISCV64.Tactic.SimpRiscV
import SSA.Projects.LLVMRiscV.Pipeline.mkRewrite

open LLVMRiscV


/-! ### sub_to_add -/

/-- 
Test the rewrite:
  (sub x, C) â†’ (add x, -C)
-/
def sub_to_add_neg50 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -50 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 50 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg49 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -49 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 49 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg48 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -48 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 48 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg47 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -47 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 47 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg46 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -46 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 46 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg45 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -45 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 45 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg44 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -44 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 44 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg43 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -43 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 43 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg42 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -42 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 42 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg41 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -41 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 41 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg40 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -40 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 40 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg39 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -39 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 39 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg38 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -38 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 38 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg37 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -37 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 37 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg36 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -36 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 36 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg35 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -35 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 35 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg34 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -34 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 34 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg33 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -33 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 33 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg32 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -32 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 32 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg31 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -31 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 31 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg30 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -30 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 30 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg29 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -29 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 29 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg28 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -28 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 28 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg27 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -27 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 27 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg26 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -26 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 26 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg25 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -25 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 25 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg24 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -24 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 24 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg23 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -23 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 23 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg22 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -22 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 22 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg21 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -21 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 21 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg20 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -20 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 20 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg19 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -19 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 19 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg18 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -18 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 18 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg17 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -17 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 17 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg16 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -16 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 16 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg15 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -15 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 15 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg14 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -14 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 14 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg13 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -13 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 13 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg12 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -12 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 12 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg11 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -11 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 11 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg10 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -10 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 10 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg9 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -9 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 9 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg8 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -8 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 8 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg7 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -7 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 7 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg6 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -6 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 6 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg5 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -5 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 5 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg4 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -4 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 4 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg3 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -3 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 3 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg2 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -2 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 2 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_neg1 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -1 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 1 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_0 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 0 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 0 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_1 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 1 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -1 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_2 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 2 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -2 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_3 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 3 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -3 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_4 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 4 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -4 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_5 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 5 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -5 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_6 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 6 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -6 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_7 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 7 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -7 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_8 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 8 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -8 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_9 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 9 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -9 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_10 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 10 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -10 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_11 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 11 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -11 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_12 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 12 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -12 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_13 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 13 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -13 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_14 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 14 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -14 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_15 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 15 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -15 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_16 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 16 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -16 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_17 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 17 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -17 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_18 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 18 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -18 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_19 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 19 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -19 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_20 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 20 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -20 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_21 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 21 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -21 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_22 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 22 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -22 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_23 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 23 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -23 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_24 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 24 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -24 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_25 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 25 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -25 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_26 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 26 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -26 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_27 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 27 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -27 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_28 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 28 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -28 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_29 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 29 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -29 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_30 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 30 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -30 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_31 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 31 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -31 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_32 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 32 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -32 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_33 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 33 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -33 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_34 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 34 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -34 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_35 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 35 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -35 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_36 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 36 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -36 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_37 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 37 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -37 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_38 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 38 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -38 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_39 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 39 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -39 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_40 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 40 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -40 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_41 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 41 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -41 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_42 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 42 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -42 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_43 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 43 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -43 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_44 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 44 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -44 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_45 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 45 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -45 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_46 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 46 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -46 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_47 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 47 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -47 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_48 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 48 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -48 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_49 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 49 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -49 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add_50 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant 50 : i64
      %1 = llvm.sub %x, %c : i64
      llvm.return %1 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant -50 : i64
      %1 = llvm.add %x, %c : i64
      llvm.return %1 : i64
  }]

def sub_to_add : List (Î£ Î“, LLVMPeepholeRewriteRefine 64 Î“) :=
  [
    âŸ¨_, sub_to_add_neg50âŸ©,
    âŸ¨_, sub_to_add_neg49âŸ©,
    âŸ¨_, sub_to_add_neg48âŸ©,
    âŸ¨_, sub_to_add_neg47âŸ©,
    âŸ¨_, sub_to_add_neg46âŸ©,
    âŸ¨_, sub_to_add_neg45âŸ©,
    âŸ¨_, sub_to_add_neg44âŸ©,
    âŸ¨_, sub_to_add_neg43âŸ©,
    âŸ¨_, sub_to_add_neg42âŸ©,
    âŸ¨_, sub_to_add_neg41âŸ©,
    âŸ¨_, sub_to_add_neg40âŸ©,
    âŸ¨_, sub_to_add_neg39âŸ©,
    âŸ¨_, sub_to_add_neg38âŸ©,
    âŸ¨_, sub_to_add_neg37âŸ©,
    âŸ¨_, sub_to_add_neg36âŸ©,
    âŸ¨_, sub_to_add_neg35âŸ©,
    âŸ¨_, sub_to_add_neg34âŸ©,
    âŸ¨_, sub_to_add_neg33âŸ©,
    âŸ¨_, sub_to_add_neg32âŸ©,
    âŸ¨_, sub_to_add_neg31âŸ©,
    âŸ¨_, sub_to_add_neg30âŸ©,
    âŸ¨_, sub_to_add_neg29âŸ©,
    âŸ¨_, sub_to_add_neg28âŸ©,
    âŸ¨_, sub_to_add_neg27âŸ©,
    âŸ¨_, sub_to_add_neg26âŸ©,
    âŸ¨_, sub_to_add_neg25âŸ©,
    âŸ¨_, sub_to_add_neg24âŸ©,
    âŸ¨_, sub_to_add_neg23âŸ©,
    âŸ¨_, sub_to_add_neg22âŸ©,
    âŸ¨_, sub_to_add_neg21âŸ©,
    âŸ¨_, sub_to_add_neg20âŸ©,
    âŸ¨_, sub_to_add_neg19âŸ©,
    âŸ¨_, sub_to_add_neg18âŸ©,
    âŸ¨_, sub_to_add_neg17âŸ©,
    âŸ¨_, sub_to_add_neg16âŸ©,
    âŸ¨_, sub_to_add_neg15âŸ©,
    âŸ¨_, sub_to_add_neg14âŸ©,
    âŸ¨_, sub_to_add_neg13âŸ©,
    âŸ¨_, sub_to_add_neg12âŸ©,
    âŸ¨_, sub_to_add_neg11âŸ©,
    âŸ¨_, sub_to_add_neg10âŸ©,
    âŸ¨_, sub_to_add_neg9âŸ©,
    âŸ¨_, sub_to_add_neg8âŸ©,
    âŸ¨_, sub_to_add_neg7âŸ©,
    âŸ¨_, sub_to_add_neg6âŸ©,
    âŸ¨_, sub_to_add_neg5âŸ©,
    âŸ¨_, sub_to_add_neg4âŸ©,
    âŸ¨_, sub_to_add_neg3âŸ©,
    âŸ¨_, sub_to_add_neg2âŸ©,
    âŸ¨_, sub_to_add_neg1âŸ©,
    âŸ¨_, sub_to_add_0âŸ©,
    âŸ¨_, sub_to_add_1âŸ©,
    âŸ¨_, sub_to_add_2âŸ©,
    âŸ¨_, sub_to_add_3âŸ©,
    âŸ¨_, sub_to_add_4âŸ©,
    âŸ¨_, sub_to_add_5âŸ©,
    âŸ¨_, sub_to_add_6âŸ©,
    âŸ¨_, sub_to_add_7âŸ©,
    âŸ¨_, sub_to_add_8âŸ©,
    âŸ¨_, sub_to_add_9âŸ©,
    âŸ¨_, sub_to_add_10âŸ©,
    âŸ¨_, sub_to_add_11âŸ©,
    âŸ¨_, sub_to_add_12âŸ©,
    âŸ¨_, sub_to_add_13âŸ©,
    âŸ¨_, sub_to_add_14âŸ©,
    âŸ¨_, sub_to_add_15âŸ©,
    âŸ¨_, sub_to_add_16âŸ©,
    âŸ¨_, sub_to_add_17âŸ©,
    âŸ¨_, sub_to_add_18âŸ©,
    âŸ¨_, sub_to_add_19âŸ©,
    âŸ¨_, sub_to_add_20âŸ©,
    âŸ¨_, sub_to_add_21âŸ©,
    âŸ¨_, sub_to_add_22âŸ©,
    âŸ¨_, sub_to_add_23âŸ©,
    âŸ¨_, sub_to_add_24âŸ©,
    âŸ¨_, sub_to_add_25âŸ©,
    âŸ¨_, sub_to_add_26âŸ©,
    âŸ¨_, sub_to_add_27âŸ©,
    âŸ¨_, sub_to_add_28âŸ©,
    âŸ¨_, sub_to_add_29âŸ©,
    âŸ¨_, sub_to_add_30âŸ©,
    âŸ¨_, sub_to_add_31âŸ©,
    âŸ¨_, sub_to_add_32âŸ©,
    âŸ¨_, sub_to_add_33âŸ©,
    âŸ¨_, sub_to_add_34âŸ©,
    âŸ¨_, sub_to_add_35âŸ©,
    âŸ¨_, sub_to_add_36âŸ©,
    âŸ¨_, sub_to_add_37âŸ©,
    âŸ¨_, sub_to_add_38âŸ©,
    âŸ¨_, sub_to_add_39âŸ©,
    âŸ¨_, sub_to_add_40âŸ©,
    âŸ¨_, sub_to_add_41âŸ©,
    âŸ¨_, sub_to_add_42âŸ©,
    âŸ¨_, sub_to_add_43âŸ©,
    âŸ¨_, sub_to_add_44âŸ©,
    âŸ¨_, sub_to_add_45âŸ©,
    âŸ¨_, sub_to_add_46âŸ©,
    âŸ¨_, sub_to_add_47âŸ©,
    âŸ¨_, sub_to_add_48âŸ©,
    âŸ¨_, sub_to_add_49âŸ©,
    âŸ¨_, sub_to_add_50âŸ©
  ]



/-! ### mul_to_shl -/

/--
Test the rewrite:
    (x * 2^n) â†’ (x << n)
-/

def mul_to_shl_1 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (1) : i64
      %0 = llvm.mul %x, %c : i64
      llvm.return %0 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (0) : i64
      %0 = llvm.shl %x, %c : i64
      llvm.return %0 : i64
  }]

def mul_to_shl_2 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (2) : i64
      %0 = llvm.mul %x, %c : i64
      llvm.return %0 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (1) : i64
      %0 = llvm.shl %x, %c : i64
      llvm.return %0 : i64
  }]

def mul_to_shl_4 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (4) : i64
      %0 = llvm.mul %x, %c : i64
      llvm.return %0 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (2) : i64
      %0 = llvm.shl %x, %c : i64
      llvm.return %0 : i64
  }]

def mul_to_shl_8 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (8) : i64
      %0 = llvm.mul %x, %c : i64
      llvm.return %0 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (3) : i64
      %0 = llvm.shl %x, %c : i64
      llvm.return %0 : i64
  }]

def mul_to_shl_16 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (16) : i64
      %0 = llvm.mul %x, %c : i64
      llvm.return %0 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (4) : i64
      %0 = llvm.shl %x, %c : i64
      llvm.return %0 : i64
  }]

def mul_to_shl_32 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (32) : i64
      %0 = llvm.mul %x, %c : i64
      llvm.return %0 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (5) : i64
      %0 = llvm.shl %x, %c : i64
      llvm.return %0 : i64
  }]

def mul_to_shl : List (Î£ Î“, LLVMPeepholeRewriteRefine 64 Î“) :=
  [
    âŸ¨_, mul_to_shl_1âŸ©,
    âŸ¨_, mul_to_shl_2âŸ©,
    âŸ¨_, mul_to_shl_4âŸ©,
    âŸ¨_, mul_to_shl_8âŸ©,
    âŸ¨_, mul_to_shl_16âŸ©,
    âŸ¨_, mul_to_shl_32âŸ©
  ]



/-! ### urem_pow2_to_mask -/

/--
Test the rewrite:
    urem(x, 2^n) -> x & (2^n - 1)
-/

def urem_pow2_to_mask_1 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (1) : i64
      %0 = llvm.urem %x, %c : i64
      llvm.return %0 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (0) : i64
      %0 = llvm.and %x, %c : i64
      llvm.return %0 : i64
  }]

def urem_pow2_to_mask_2 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (2) : i64
      %0 = llvm.urem %x, %c : i64
      llvm.return %0 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (1) : i64
      %0 = llvm.and %x, %c : i64
      llvm.return %0 : i64
  }]

def urem_pow2_to_mask_4 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (4) : i64
      %0 = llvm.urem %x, %c : i64
      llvm.return %0 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (3) : i64
      %0 = llvm.and %x, %c : i64
      llvm.return %0 : i64
  }]

def urem_pow2_to_mask_8 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (8) : i64
      %0 = llvm.urem %x, %c : i64
      llvm.return %0 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (7) : i64
      %0 = llvm.and %x, %c : i64
      llvm.return %0 : i64
  }]

def urem_pow2_to_mask_16 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (16) : i64
      %0 = llvm.urem %x, %c : i64
      llvm.return %0 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (15) : i64
      %0 = llvm.and %x, %c : i64
      llvm.return %0 : i64
  }]

def urem_pow2_to_mask_32 : LLVMPeepholeRewriteRefine 64 [Ty.llvm (.bitvec 64)] where
  lhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (32) : i64
      %0 = llvm.urem %x, %c : i64
      llvm.return %0 : i64
  }]
  rhs := [LV| {
    ^entry (%x: i64):
      %c = llvm.mlir.constant (31) : i64
      %0 = llvm.and %x, %c : i64
      llvm.return %0 : i64
  }]

def urem_pow2_to_mask : List (Î£ Î“, LLVMPeepholeRewriteRefine 64 Î“) :=
  [
    âŸ¨_, urem_pow2_to_mask_1âŸ©,
    âŸ¨_, urem_pow2_to_mask_2âŸ©,
    âŸ¨_, urem_pow2_to_mask_4âŸ©,
    âŸ¨_, urem_pow2_to_mask_8âŸ©,
    âŸ¨_, urem_pow2_to_mask_16âŸ©,
    âŸ¨_, urem_pow2_to_mask_32âŸ©
  ]
